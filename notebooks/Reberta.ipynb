{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1a5541",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'miners.text.server.server_gpt2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1521/959264308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mminers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_gpt2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'miners.text.server.server_gpt2'"
     ]
    }
   ],
   "source": [
    "import bittensor\n",
    "import torch \n",
    "from transformers import AutoTokenizer,AutoModel,AutoConfig\n",
    "import numpy as np\n",
    "from miners.text.server.server_gpt2 import server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4aa4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = AutoConfig.from_pretrained('bert-base-uncased')\n",
    "model =  AutoModel.from_config(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "847a015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.8.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50378\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.vocab_size=bittensor.__vocab_size__\n",
    "\n",
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cadcdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2021-09-27 12:15:32.053\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Set debug:          \u001b[32mON\u001b[0m\n",
      "\u001b[34m2021-09-27 12:15:32.057\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Set trace:          \u001b[31mOFF\u001b[0m\n",
      "\u001b[34m2021-09-27 12:15:32.057\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Set record log:     \u001b[31mOFF\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logging=bittensor.logging(debug=True)\n",
    "dataload = bittensor.dataloader(max_corpus_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19973b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7673d88f8fe04b1e87e202373a013a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5b356f335f44cb869fe098760e87bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9dafb40b8e4d4298399963e76d0e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = bittensor.tokenizer.prep_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f656fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "configuration = RobertaConfig()\n",
    "print(configuration)\n",
    "\n",
    "model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e88f619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Epoch 0\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10, 23])\n",
      "torch.Size([10, 23, 768])\n",
      "[[4.90156794e-03 7.45583236e-01 8.49807382e-01 8.13194871e-01\n",
      "  8.32298279e-01 8.62561882e-01 7.99810767e-01 8.51298153e-01\n",
      "  8.71891558e-01 7.90471494e-01 8.74624789e-01 8.54153752e-01\n",
      "  8.73166382e-01 8.94730031e-01 8.05655062e-01 8.76586735e-01\n",
      "  8.39517295e-01 8.61511588e-01 8.79324377e-01 8.05350065e-01\n",
      "  7.92445481e-01 7.28426635e-01]\n",
      " [7.18522310e-01 4.68406528e-02 5.55727303e-01 7.50683367e-01\n",
      "  8.03008974e-01 7.40701854e-01 7.53103137e-01 7.81263411e-01\n",
      "  7.58184552e-01 7.39218950e-01 7.77169466e-01 8.19601357e-01\n",
      "  7.44507372e-01 7.75144398e-01 7.32451081e-01 7.62196422e-01\n",
      "  7.79491365e-01 7.73935735e-01 8.09823036e-01 7.66353846e-01\n",
      "  7.14990556e-01 6.94091439e-01]\n",
      " [6.82936847e-01 7.09711492e-01 1.26951262e-01 3.52642417e-01\n",
      "  7.19457984e-01 6.94990695e-01 7.19207466e-01 7.10464895e-01\n",
      "  7.34698713e-01 6.84679329e-01 7.21040606e-01 7.49381065e-01\n",
      "  7.04908729e-01 6.88450873e-01 6.82036817e-01 7.11028397e-01\n",
      "  7.05802083e-01 6.77800894e-01 7.40457594e-01 7.23447621e-01\n",
      "  6.51872694e-01 6.14616334e-01]\n",
      " [6.51196420e-01 7.16583371e-01 6.95848227e-01 2.51531661e-01\n",
      "  2.05902562e-01 6.85321093e-01 6.67999864e-01 6.78173661e-01\n",
      "  6.96840048e-01 6.70815647e-01 6.92373157e-01 7.10536301e-01\n",
      "  6.77875519e-01 6.89221680e-01 6.77839100e-01 6.78410292e-01\n",
      "  6.88805282e-01 6.76367879e-01 7.43996084e-01 7.04547942e-01\n",
      "  6.78368032e-01 6.31289542e-01]\n",
      " [7.11370707e-01 7.22899973e-01 7.16003716e-01 7.09552467e-01\n",
      "  4.17343646e-01 9.67506990e-02 6.84243858e-01 6.97727084e-01\n",
      "  7.30502844e-01 6.87230051e-01 7.30610967e-01 7.39232242e-01\n",
      "  7.04215765e-01 7.56745577e-01 6.75799787e-01 6.99877143e-01\n",
      "  7.12459981e-01 6.86244905e-01 7.38516986e-01 7.04778671e-01\n",
      "  6.65412903e-01 6.87091172e-01]\n",
      " [7.42530584e-01 7.75047958e-01 8.23712111e-01 7.61224747e-01\n",
      "  7.82381296e-01 5.95298350e-01 2.67857630e-02 7.89995968e-01\n",
      "  7.95551062e-01 7.05596268e-01 7.99493790e-01 8.10646474e-01\n",
      "  7.81797171e-01 8.08489621e-01 7.44060874e-01 7.76755512e-01\n",
      "  7.91553378e-01 8.08292508e-01 7.97644496e-01 7.55729020e-01\n",
      "  7.50958979e-01 7.42005408e-01]\n",
      " [8.85278463e-01 9.21771765e-01 9.11458969e-01 8.80423725e-01\n",
      "  8.85421455e-01 8.71293843e-01 8.75474691e-01 5.75595885e-04\n",
      "  9.21291173e-01 8.72803688e-01 9.06921089e-01 9.29785371e-01\n",
      "  8.51322055e-01 8.91333580e-01 8.91235888e-01 8.76462340e-01\n",
      "  9.06371951e-01 8.81010115e-01 9.25074995e-01 9.02535379e-01\n",
      "  8.50115955e-01 8.35779727e-01]\n",
      " [8.23581934e-01 8.05506468e-01 8.57538044e-01 8.11013758e-01\n",
      "  8.30460191e-01 8.23996007e-01 8.07809174e-01 8.38505387e-01\n",
      "  1.42771965e-02 6.99582696e-01 8.30151498e-01 8.69988382e-01\n",
      "  8.45429540e-01 9.12242830e-01 8.16449463e-01 8.36434960e-01\n",
      "  8.50391150e-01 8.32067847e-01 8.61008227e-01 8.31875205e-01\n",
      "  8.16958129e-01 7.82954037e-01]\n",
      " [6.98919892e-01 7.37438083e-01 7.43215024e-01 7.18658984e-01\n",
      "  7.44190097e-01 7.19976187e-01 6.78109348e-01 7.33768046e-01\n",
      "  7.48576522e-01 6.53389618e-02 4.54134494e-01 7.41441965e-01\n",
      "  7.42868662e-01 7.40266919e-01 6.70460284e-01 7.06710577e-01\n",
      "  7.32416570e-01 7.29125381e-01 7.80538797e-01 7.17922091e-01\n",
      "  7.06427455e-01 6.85975134e-01]\n",
      " [6.95938230e-01 7.27889478e-01 7.30605304e-01 6.93333030e-01\n",
      "  7.05320299e-01 7.08069503e-01 7.01278269e-01 7.11294413e-01\n",
      "  7.28272080e-01 6.53935134e-01 1.68553352e-01 3.08528006e-01\n",
      "  7.18940377e-01 7.19946265e-01 6.64399922e-01 6.79876387e-01\n",
      "  7.31816351e-01 7.01480985e-01 7.61313140e-01 7.19430804e-01\n",
      "  6.75674796e-01 6.86510205e-01]\n",
      " [6.80980265e-01 6.90865397e-01 7.04554260e-01 6.69950485e-01\n",
      "  6.80550694e-01 6.74140930e-01 6.77020490e-01 6.62948251e-01\n",
      "  7.18160987e-01 6.68795347e-01 6.75731778e-01 3.29869956e-01\n",
      "  1.80212796e-01 6.71053946e-01 6.77337766e-01 6.78240657e-01\n",
      "  6.96177065e-01 6.96570396e-01 7.18141317e-01 7.15164125e-01\n",
      "  6.72426224e-01 6.42108798e-01]\n",
      " [7.76654541e-01 7.60738492e-01 7.31978297e-01 7.28757203e-01\n",
      "  7.49955118e-01 7.78838694e-01 7.48286247e-01 7.28491843e-01\n",
      "  8.32101703e-01 7.35429406e-01 7.50042975e-01 8.06224883e-01\n",
      "  4.58177269e-01 6.59212545e-02 7.45474219e-01 7.51381755e-01\n",
      "  7.21337497e-01 7.68012226e-01 7.84773886e-01 7.96441376e-01\n",
      "  7.35363960e-01 7.34946609e-01]\n",
      " [7.75192320e-01 8.00247848e-01 7.94511676e-01 7.93823004e-01\n",
      "  8.18289220e-01 7.71476924e-01 7.79649794e-01 8.14394176e-01\n",
      "  8.40985000e-01 7.38653064e-01 7.84544170e-01 8.19064200e-01\n",
      "  8.21037471e-01 7.01194465e-01 1.43100917e-02 8.07986677e-01\n",
      "  7.87597060e-01 8.00884128e-01 7.94197440e-01 7.98116505e-01\n",
      "  7.37463951e-01 7.72660196e-01]\n",
      " [9.15594876e-01 8.98023725e-01 9.16288614e-01 8.74579370e-01\n",
      "  8.93306196e-01 8.72555673e-01 8.83476555e-01 8.77677679e-01\n",
      "  9.23348129e-01 8.55671108e-01 8.63321722e-01 9.19933677e-01\n",
      "  8.86432528e-01 9.08714473e-01 8.82540286e-01 5.59879176e-04\n",
      "  8.51602793e-01 8.96212757e-01 9.56802368e-01 8.89261484e-01\n",
      "  8.94353330e-01 8.62920225e-01]\n",
      " [7.70017385e-01 8.14733624e-01 7.91079104e-01 7.66973317e-01\n",
      "  7.98942685e-01 7.68461645e-01 7.94944823e-01 7.93907940e-01\n",
      "  8.24547410e-01 7.61584878e-01 8.05459321e-01 8.49325180e-01\n",
      "  7.80264139e-01 7.70036995e-01 7.58160532e-01 7.69338667e-01\n",
      "  2.76706237e-02 6.14971936e-01 8.16953599e-01 7.75722384e-01\n",
      "  7.41788685e-01 7.54323602e-01]\n",
      " [7.26751864e-01 7.61640489e-01 7.03479350e-01 7.24507093e-01\n",
      "  7.30281055e-01 6.94000602e-01 7.40936220e-01 7.18841970e-01\n",
      "  7.48103559e-01 7.07505465e-01 7.51875818e-01 7.48836160e-01\n",
      "  7.49143898e-01 7.48761415e-01 6.93601668e-01 7.39790261e-01\n",
      "  7.22378790e-01 9.55182090e-02 4.12032515e-01 7.27178872e-01\n",
      "  6.57758594e-01 6.96675837e-01]\n",
      " [6.68713331e-01 7.22644269e-01 7.04821646e-01 7.24183261e-01\n",
      "  7.18031526e-01 6.78805172e-01 6.70713067e-01 7.05813289e-01\n",
      "  7.20732450e-01 6.76707804e-01 7.29306340e-01 7.48774886e-01\n",
      "  7.13798106e-01 7.39216924e-01 6.53653026e-01 7.15077221e-01\n",
      "  6.98987067e-01 6.81550145e-01 2.09797472e-01 2.56289214e-01\n",
      "  6.41342044e-01 6.69139743e-01]\n",
      " [6.49535000e-01 6.93140626e-01 6.82115436e-01 6.90785527e-01\n",
      "  7.28965521e-01 6.50774598e-01 6.79037392e-01 6.87501013e-01\n",
      "  7.23618746e-01 6.75152481e-01 6.85738266e-01 7.55045652e-01\n",
      "  7.06858635e-01 7.34816253e-01 6.44108891e-01 7.10053682e-01\n",
      "  6.81808352e-01 6.71644986e-01 6.88873649e-01 3.41553241e-01\n",
      "  1.22959159e-01 6.27809346e-01]\n",
      " [6.58425927e-01 7.27440894e-01 6.96380734e-01 6.92439914e-01\n",
      "  7.63558447e-01 7.33805954e-01 7.29936898e-01 7.21562564e-01\n",
      "  7.56826222e-01 7.09126830e-01 7.60130942e-01 7.89077520e-01\n",
      "  7.26448596e-01 7.85348356e-01 7.16641784e-01 7.52373815e-01\n",
      "  7.43292451e-01 7.37447679e-01 7.65679240e-01 7.43375123e-01\n",
      "  4.81124252e-01 4.05527949e-02]\n",
      " [7.46001005e-01 7.91111529e-01 8.14288914e-01 7.95789123e-01\n",
      "  8.50909412e-01 8.29382181e-01 7.81711221e-01 7.85194933e-01\n",
      "  8.32747281e-01 7.90309191e-01 8.39231551e-01 8.52458358e-01\n",
      "  7.90591002e-01 7.88027585e-01 7.92684257e-01 8.32445979e-01\n",
      "  8.10087502e-01 8.29953015e-01 8.37578416e-01 8.48586500e-01\n",
      "  7.70558596e-01 6.68196261e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athrunxyz/.bittensor/env/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "for epoch in np.arange(1):\n",
    "    print('New Epoch',epoch)\n",
    "    for test in dataload.dataloader(epoch_length=1):\n",
    "        #decoded = [bittensor.tokenizer().decode(i) for i in test[0]]\n",
    "\n",
    "        new_data = remapping(test,bittensor.tokenizer(),tokenizer)\n",
    "        print(test.size())\n",
    "        print(new_data.size())\n",
    "        rep = model(new_data)\n",
    "        print(rep.last_hidden_state.shape)\n",
    "        down= F.interpolate(rep.last_hidden_state.unsqueeze(1),size=[20,768],mode='bilinear')\n",
    "        collect = np.zeros((20,22))\n",
    "        for i in range(20):\n",
    "            for j in range(22):\n",
    "                collect[i,j] = F.mse_loss(down[:,0,i,:],rep.last_hidden_state[:,j,:]).item()\n",
    "\n",
    "    #print(model(test[j]))\n",
    "print(collect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3afbbaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from seaborn) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from seaborn) (1.21.0)\n",
      "Collecting scipy>=1.0\n",
      "  Downloading scipy-1.7.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.4 MB 35.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: six in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/athrunxyz/.bittensor/env/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Installing collected packages: scipy, seaborn\n",
      "Successfully installed scipy-1.7.1 seaborn-0.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7403656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(collect, linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71579589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class server(torch.nn.Module):\n",
    "    def __init__(self, pretrained,pre_dimension,final_dim ):\n",
    "        super(server, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        self.final_dim =  final_dim\n",
    "        self.pre_dimension = pre_dimension\n",
    "        self.mapping = torch.nn.Linear( pre_dimension, final_dim)\n",
    "        self.decoder = torch.nn.Linear( final_dim, bittensor.__vocab_size__ , bias=False)\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, inputs,target):\n",
    "        pre_hidden = self.pretrained(inputs).last_hidden_state\n",
    "        down= F.interpolate(pre_hidden.unsqueeze(1),size=[20,768])\n",
    "        padding_l = (self.final_dim-self.pre_dimension)//2\n",
    "        padding_r = (self.final_dim-self.pre_dimension) - padding_l\n",
    "        encoded_hidden = F.pad(down.squeeze(1), (padding_l, padding_r),  \"constant\", 0)\n",
    "        #encoded_hidden = self.mapping(down.squeeze(1).detach())\n",
    "        decoded_targets = self.decoder(encoded_hidden)\n",
    "        \n",
    "        shift_logits = decoded_targets[..., :-1, :].contiguous()\n",
    "        shift_labels = target[..., 1:].contiguous()     \n",
    "        loss = self.loss_fct( shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1) ) \n",
    "        return loss, decoded_targets\n",
    "    \n",
    "    def encode_forward(self,inputs):\n",
    "        pre_hidden = self.pretrained(inputs).last_hidden_state\n",
    "        padding_l = (self.final_dim-self.pre_dimension)//2\n",
    "        padding_r = (self.final_dim-self.pre_dimension) - padding_l\n",
    "        encoded_hidden = F.pad(pre_hidden, (padding_l, padding_r),  \"constant\", 0)\n",
    "        return encoded_hidden\n",
    "\n",
    "def remapping(input, old_token,new_token):\n",
    "    new_data = []\n",
    "    for i in range(input.shape[0]):\n",
    "        decoded = old_token.decode(input[i]) \n",
    "        hugging = new_token(decoded)\n",
    "        new_data += [torch.LongTensor(hugging.input_ids)]\n",
    "    new_data = pad_sequence(new_data,batch_first=True)\n",
    "    return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c069f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)\n",
    "dimension = model.config.hidden_size\n",
    "bit_dim =  bittensor.__network_dim__\n",
    "gp_server = server(model,dimension,bit_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c5bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    [ {\"params\": gp_server.parameters()} ],\n",
    "    lr = 0.05,\n",
    "    momentum = 0.9,\n",
    ")\n",
    "scheduler= torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "    step_size= 1.0,\n",
    "    gamma=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c985fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "\u001b[34m2021-09-21 09:00:03.623\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Retrieving a dataset files from the IPFS gateway...\n",
      "\u001b[34m2021-09-21 09:00:04.094\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Loaded folder:      \u001b[34mQmXwfPoh2QFYqC6cYcW8kzyd9ruFfhnUi2kVBkdhawjUzj\u001b[0m\n",
      "\u001b[34m2021-09-21 09:00:06.526\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Loaded folder:      \u001b[34mQmRjFNn3XpYMycVzTE4YcVcxk45vNZcTAjKmtEqPLKwAWd\u001b[0m\n",
      "\u001b[34m2021-09-21 09:00:06.929\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Downloaded:         \u001b[34mWikitext_Bandedsugarant.txt\u001b[0m\n",
      "\u001b[34m2021-09-21 09:00:06.930\u001b[0m | \u001b[32m\u001b[1m    SUCCESS     \u001b[0m | Saved:              \u001b[34mWikitext_Bandedsugarant.txt\u001b[0m\n",
      "10.826314926147461\n",
      "8.877348899841309\n",
      "7.353959560394287\n",
      "7.038410186767578\n",
      "6.644811153411865\n",
      "6.9440083503723145\n",
      "6.314007759094238\n",
      "5.95612907409668\n",
      "6.092041015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_297/3826558591.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_server\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.bittensor/env/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.bittensor/env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "for k in range(5):\n",
    "    print(\"epoch:\",k)\n",
    "    epoch_loss = 0\n",
    "    epoch_batches = dataload.dataloader(epoch_length=100)\n",
    "    for iteration, inputs in enumerate(epoch_batches):\n",
    "        optimizer.zero_grad()\n",
    "        new_data = remapping(inputs,bittensor.tokenizer(),tokenizer)\n",
    "        loss, _ = gp_server( new_data,inputs )\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(gp_server.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if iteration % 10 == 1:\n",
    "            print(loss.item())\n",
    "    print(loss)\n",
    "    print(epoch_loss/100)\n",
    "    print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134ccca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
